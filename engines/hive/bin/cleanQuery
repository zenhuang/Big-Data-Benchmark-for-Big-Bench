#!/usr/bin/env bash

#"INTEL CONFIDENTIAL"
#Copyright 2016 Intel Corporation All Rights Reserved.
#
#The source code contained or described herein and all documents related to the source code ("Material") are owned by Intel Corporation or its suppliers or licensors. Title to the Material remains with Intel Corporation or its suppliers and licensors. The Material contains trade secrets and proprietary and confidential information of Intel or its suppliers and licensors. The Material is protected by worldwide copyright and trade secret laws and treaty provisions. No part of the Material may be used, copied, reproduced, modified, published, uploaded, posted, transmitted, distributed, or disclosed in any way without Intel's prior express written permission.
#
#No license under any patent, copyright, trade secret or other intellectual property right is granted to or conferred upon you by disclosure or delivery of the Materials, either expressly, by implication, inducement, estoppel or otherwise. Any license under such intellectual property rights must be express and approved by Intel in writing.

helpModule () {
  echo "This module cleans all query results from HDFS as well as from the metastore for one query"
  echo
  echo "Options:"
  echo -e "-d\tdatabase to use"
  echo -e "-h\tshow this help"
  echo
  echo "INTERNAL options:"
  echo -e "-q\tquery number to run (required)"
  echo -e "-p\tbenchmark phase to use"
  echo -e "-t\tstream number for query run"
  echo -e "-z\tfile with user defined engine settings"
}

runModule () {
  if ! initQueryEnv
  then
    return 1
  fi

  echo "==============================================="
  echo "Cleaning query : $QUERY_NAME"
  echo "-----------------------------------------------"
  echo "benchmark phase: $BIG_BENCH_BENCHMARK_PHASE"
  echo "stream number  : $BIG_BENCH_STREAM_NUMBER"
  echo "user parameter file: $USER_QUERY_PARAMS_FILE"
  echo "user settings file : $USER_ENGINE_SETTINGS_FILE"
  if [ -n "$DEBUG_QUERY_PART" ]
  then
    echo "query part to debug: $DEBUG_QUERY_PART"
  fi
  echo "log: $LOG_FILE_NAME"
  echo "==============================================="

  ### Checking required folder: logs/; tmp/; result/ if they exist, create them and set permissions

  # Run the clean method implemented in the query's run.sh
  runCmdWithErrorCheck "$QUERY_CLEAN_METHOD"

  if [ "$BIG_BENCH_USE_SNAKEBITE_HDFSCLIENT" -ne 0 ]
  then
    echo "cleaning dir $RESULT_DIR"
    snakebite rm -R -S "$RESULT_DIR"

    echo "cleaning dir $TEMP_DIR"
    snakebite rm -R -S "$TEMP_DIR"
  else
    echo "cleaning dir $RESULT_DIR"
    hadoop fs -rm -r -f -skipTrash "$RESULT_DIR"

    echo "cleaning dir $TEMP_DIR"
    hadoop fs -rm -r -f -skipTrash "$TEMP_DIR"
  fi
  wait

  echo "cleaning log $LOG_FILE_NAME"
  rm -rf "$LOG_FILE_NAME"
}
